---
title: "Open OGC Geoservices in Switzerland"
subtitle: "Exploratory Analysis of the available OGC services"
date: today
output-dir: docs
format:
  html:
    embed-resources: true
editor: visual
execute:
  echo: false
  warning: false
  message: false
---

# OGC Webservices in Switzerland

This document explores the OGC webservices provided by the various public open data provider. These OGC webservices are publicly available and provide broad and well maintained metadata of the content they portray. The analysis is based on the harvested OGC Web Services (WMS, WMTS, WFS) of Switzerland in <https://github.com/FHNW-IVGI/Geoharvester> initiated by <https://github.com/davidoesch/geoservice_harvester_poc> by [David Oesch](https://github.com/davidoesch). The *GeoHarvester* crawls the known OGC web services managed by the state, cantons and communes.

```{r directorySetup,comment=FALSE, message = FALSE, echo=FALSE,warning=FALSE}
# rm(list=ls())         # Clean the environment (comment out, if batch script)
options(scipen=999)     # display digits proberly!! not the scientific version
options(digits.secs=6)  # use milliseconds in Date/Time data types
options(warning=FALSE)  # don't show warnings
library(knitr)          # set global knitr options of the document
# memory.limit(size=1800) # set memory limit 

# Libraries
library(rgdal)# install.packages("rgdal") # install libraries
library(dplyr)
library(tidyr)
library(stringr)
library(sf)
library(ggplot2)
library(ggrepel) # https://github.com/slowkow/ggrepel/issues/89
library(RColorBrewer)
library(igraph)
library(kableExtra) # http://haozhu233.github.io/kableExtra/best_practice_for_newline_in_latex_table.pdf
options(kableExtra.auto_format = TRUE)
library(tm)


# Folders
dataFolder   <- file.path("data")   # Set path to the data and figure folder
resultFolder <- file.path("result") # Set path to the data and figure folder
# Settings
themeReport <- theme_minimal() # customise plot theme
colorPal <- c("#ddf1da","#abdda4","#e6f598","#fee08b","#fdae61","#f46d43","#d53e4f") # set a color palette for the map


colorPrimary <- "#1f78b4"
caption <- "Data Source: OGC Webservices Switzerland"
```

```{r readdata}
# Set file paths
# Read CSV from GitHub Repositories: 
# replace github.com with raw.githubusercontent.com and remove blob/ in the url
# geoCHPath = "https://raw.githubusercontent.com/davidoesch/geoservice_harvester_poc/main/data/geoservices_CH.csv"
geoCHPath = "https://raw.githubusercontent.com/FHNW-IVGI/Geoharvester/main/scraper/data/geoservices_CH.csv"

# local file
# geoCHPath <- file.path(dataFolder,"geoservices_CH.csv")

# read files
geoCH <- read.csv(geoCHPath, stringsAsFactors = FALSE, encoding="UTF-8")

# Entferne ungÃ¼ltig endpoints
geoCH <- geoCH %>% mutate(endpointInvalid = is.na(endpoint)| endpoint=="")
geoCH <- geoCH %>% filter(!endpointInvalid)

# Read Spatial data
cantonShapeFile <- file.path(dataFolder,"BFS_GGG/k4k20.shp")
lakeShapeFile <- file.path(dataFolder,"BFS_GGG/k4s20.shp")
cantonSF <- st_read(dsn = cantonShapeFile,stringsAsFactors = FALSE,quiet=TRUE)
lakesSF <- st_read(dsn = lakeShapeFile,stringsAsFactors = FALSE,quiet=TRUE)
```

## Dataset

| Dataset             | Description                                   |
|---------------------|-----------------------------------------------|
| geoservices_CH.csv  | OGC Services of Switzerland full dataset      |

Random Example of a dataset
```{r}
id <- sample.int(nrow(geoCH),1) # random service
d <- data.frame(key=names(geoCH),example=as.character(geoCH[id,]))
knitr::kable(d, digits = 2,row.names=FALSE, col.names = c("Key","OGC Service Example"),caption = "Field names and OGC Service Value Example", booktabs = TRUE,caption.short = "Random OGC Service") %>% column_spec(2,width="8 cm") %>%  kable_classic(font_size = 12)
```

**Spatial Datasets**

The Federal Statistical office BFS provides generalized boundaries of local and regional authorities. The data sets are particularly suitable for visualising statistical data on communes, districts and cantons as well as for creating small scale maps relating to different topics.

BFS Generalisierte Gemeindegrenzen der Schweiz [BFS Generalisierte Gemeindegrenzen der Schweiz 2020](https://www.bfs.admin.ch/bfs/de/home/dienstleistungen/geostat/geodaten-bundesstatistik/administrative-grenzen/generalisierte-gemeindegrenzen.assetdetail.14776419.html),[Dataset](https://www.bfs.admin.ch/bfsstatic/dam/assets/14776419/master)]

## Distribution of Content by Service Owners

How many layers do the various service provider offer? How are the services structured?

```{r}
# d <- geoCH %>% group_by(provider) %>% summarise(layers = length(unique(title)), links = length(unique(endpoint)))
d <- geoCH %>% group_by(provider,service) %>% summarise(layers = length(unique(title)), links = length(unique(endpoint)))
d$provider <- gsub("KT_","",d$provider)
d$provider <- gsub("FL_","",d$provider)
d2 <- d
d <- d2 %>% group_by(provider) %>% summarise(layers=sum(layers),links=sum(links))

# count number of unique layers and their service offers for each provider and summarise for each provider
dunique <- geoCH %>%
  group_by(provider,endpoint,title,name) %>%
  distinct(title, pick("service","name")) %>%
  group_by(provider,title) %>%
  summarise(WMS=ifelse(sum(service=="WMS")>0,1,0),
            WMTS=ifelse(sum(service=="WMTS")>0,1,0),
            WFS=ifelse(sum(service=="WFS")>0,1,0)) %>%
  mutate(layerservice= WMS*100+WMTS*10+WFS*1) %>%
  group_by(provider) %>%
  count(layerservice)  %>% 
  mutate(ls = case_match(
  layerservice,
  10 ~ "WMTS",
  100 ~ "WMS",
  110 ~ "WMS+WMTS",
  1 ~ "WFS",
  101 ~ "WMS+WFS")) %>% 
  select(-layerservice) %>% 
  pivot_wider(names_from="ls",values_from = n,values_fill = 0) %>% 
  mutate(provider= str_replace(provider,"_"," "))
# %>% mutate(prop = prop.table(n))


# Investigating the use of the group / tree element usage by service providers
dgroup <- lapply(unique(geoCH$provider),function(provider){
  # iterate over all entries with groups and count number of unique group entries, titles remaining and number of unique titles
  d  <- geoCH %>% filter(provider==!!provider) 
  total <- d %>% nrow()
  unique_titles  <- d %>% distinct(title) %>% nrow()
  unique_names  <- d %>% distinct(name) %>% nrow()
  trees  <- d %>% distinct(tree) %>% nrow()
  groups <- d %>% filter(group!="") %>% distinct(group) %>% nrow() # number of unique group names
  unique_title_without_groups <- d %>% filter(group=="") %>% distinct(title) %>% nrow() # number of unique titles
  # anyNA <- sum(is.na(d$group)) # check if there are groups with NA entries
  return(data.frame(provider,total,unique_titles,unique_names,groups,trees,unique_title_without_groups))
})
dgroup <- bind_rows(dgroup) %>% arrange(provider)
# dgroup <- dgroup %>% mutate(title_group=uniqueTitleWOgroups+groups)

# dbund <- geoCH %>% filter(provider=="Bund") %>% select(provider,name,title,service,group,tree,endpoint) %>% arrange(group)
# dbund %>% group_by(group) %>% count(group) %>% filter(n>1) %>% data.frame()
# dbund %>% group_by(tree) %>% count(tree) %>% filter(n>1) %>% data.frame()
# 
# dtg <- geoCH %>% filter(provider=="KT_TG") %>% select(provider,name,title,service,group,tree,endpoint) %>% arrange(group)
# dtg %>% group_by(group) %>% count(group) %>% filter(n>1) %>% data.frame()
# dtg %>% filter(group=="Landwirtschaft_Kulturflaechen")

# The following counts should correspond in numbers, if both, service layers names and title are unique for each dataset
# However the WMS server of KT_FR has "0" as layer name, hence counting over service title is the better approach.
# geoCH %>% group_by(provider, service) %>% summarise(n=length(unique(name))) %>% data.frame()
# geoCH %>% group_by(provider, service) %>% summarise(n=length(unique(title))) %>% data.frame()

dnameInvalid <- geoCH %>% group_by(provider, name) %>% distinct(title) %>% mutate(nameInvalid=ifelse(is.na(name)|name==""|name=="0",1,0)) %>% group_by(provider) %>% summarise(nameInvalid=sum(nameInvalid,na.rm=T)) %>% filter(nameInvalid>0)
```

Number of unique layer titles by provider and service `r sum(d$layers)` and total number of layers in total `r nrow(geoCH)`.

```{r}
#| fig-cap: Number of unique Layers provided by each service owner 
#| fig-height: 5
plot1 <- ggplot(data = d, aes(x=reorder(provider,layers), y= layers)) + 
  geom_bar(stat = "identity",fill=colorPrimary) + 
  geom_text(aes(label = layers), nudge_y = 2,size=3, color = "black", hjust = -0.2) +
  scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
  theme(axis.line.x = element_line(linewidth = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  # labs(title = "Verteilung des Geodiensteangebots", subtitle= "Anzahl Geodatenlayer nach Provider",
  #      x = NULL,y = "Anzahl eindeutige Layer",fill="",caption=caption)
  labs(title = "Datasets by Service Provider", subtitle= "Number of layers by Service Provider",
  x = NULL,y = "Number of Layers",fill="",caption=caption)
```

```{r}
#| fig-cap: Number of unique service links provided by each service owner 
#| fig-height: 6
plot2 <- ggplot(data = d, aes(x=reorder(provider,links), y= links)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  geom_text(aes(label = links), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
  scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
  theme(axis.line.x = element_line(linewidth = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  # labs(title = "Verteilung der Geodatenserver", subtitle= "Anzahl Service Endpoints nach Provider",
  #      x = NULL,y = "Anzahl Service Endpoints",fill="",caption=caption)
  labs(title = "Distribution of Service Endpoints", subtitle= "Number of Service Endpoints by Service Provider",
  x = NULL,y = "Number of Service Endpoints",fill="",caption=caption)
```

```{r}
library(cowplot)
plot_grid(plot1, plot2, labels = c('a)', 'b)'), label_size = 10, label_y=0.01, label_fontface = "plain")
```

```{r}
#| fig-cap: Number of unique Layers provided by each service owner 
#| fig-height: 5
plot1 <- ggplot(data = d2, aes(x=reorder(provider,layers), y= layers,fill=service)) + 
  geom_bar(stat = "identity") + #,fill=colorPrimary
  # geom_text(aes(label = layers), nudge_y = 2,size=3, color = "black", hjust = -0.2) +
  scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  scale_fill_manual(values = c("WMS"="#2166ac","WMTS"="#67a9cf","WFS"="#7fbf7b"), na.value = "#666666")+
  coord_flip() +
  theme(axis.line.x = element_line(linewidth = .2),panel.background = element_blank(),axis.ticks.y=element_blank(),legend.position = "none")+
  # labs(title = "Verteilung des Geodiensteangebots", subtitle= "Anzahl Geodatenlayer nach Provider",
  #      x = NULL,y = "Anzahl eindeutige Layer",fill="",caption=caption)
  labs(title = "Layers and Service Type", subtitle= "Service Distribution by Service Provider",
  x = NULL,y = "Number of Layers",fill="",caption=caption)
```

```{r}
#| fig-cap: Number of unique service links provided by each service owner 
#| fig-height: 6
plot2 <- ggplot(data = d2, aes(x=reorder(provider,links), y= links,fill=service)) + 
  geom_bar(stat = "identity") + #,fill=colorPrimary
  # geom_text(aes(label = links), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
  scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  scale_fill_manual(values = c("WMS"="#2166ac","WMTS"="#67a9cf","WFS"="#7fbf7b"), na.value = "#666666")+
  coord_flip() +
  theme(axis.line.x = element_line(linewidth = .2),panel.background = element_blank(),axis.ticks.y=element_blank(),legend.position = c(0.9, 0.2))+
  # labs(title = "Verteilung der Geodatenserver", subtitle= "Anzahl Service Endpoints nach Provider",
  #      x = NULL,y = "Anzahl Service Endpoints",fill="",caption=caption)
  labs(title = "Service Endpoints", subtitle= "Service Distribution by Service Provider",
  x = NULL,y = "Number of Service Endpoints",fill="",caption=caption)
```

```{r}
#| fig-cap: a) Number of Layers provided by each service owner, b) Number of unique service links provided by each service owner 
#| fig-height: 6
library(cowplot)
plot_grid(plot1, plot2, labels = c('a)', 'b)'), label_size = 10, label_y=0.01, label_fontface = "plain")
```


```{r}
#| fig-cap: Number of unique service links provided by each service owner 
#| fig-height: 4
ggplot(data = d, aes(x=layers, y= links)) + 
  geom_point(size=1,color=colorPrimary)+
  # geom_text(aes(label = provider), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
  geom_text_repel(mapping = aes(x = layers,y = links,label = provider),size = 2.4,
                  min.segment.length = 0,point.padding = 0.5,segment.color = "grey30", max.overlaps=20) + 
  # themeReport +labs(x = "Anzahl Layer",y = "Anzahl Service Endpoints",
  #                   title = "Vergleich der Anzahl Layer zu Service Endpoints", caption=caption)
  themeReport +labs(x = "Number of Layers",y = "Number of Service Endpoints",
                    title = "Number of Service Endpoints vs Layers", caption=caption)
```
```{r}
d2w <- d2 %>% pivot_wider(names_from="service",values_from = c("layers","links"),values_fill = 0) %>% arrange(desc(layers_WMS))
knitr::kable(d2w,caption = "Overview on geoservice provider and services", booktabs = TRUE, col.names = names(d2w) %>% str_replace("_"," ")%>% str_replace("links","endpoints")) %>%  kable_classic(font_size = 10)
```

The following table provides an overview of unique datasets (by title) for each service provider and service offered for each of them. Most of the datasets are uniquely offered as WMS service. This might be good for raster data and and maps, for vector for vector datasets, these should also be offered as a WFS in addition to a WMS or WMTS service. Column WFS with unique WFS layers have likely a WMS or WMTS service with a different title. 
Canton Fribourg uses for their services with single layers no unique name field and names them *"0"*, hence the service *title* is used for the counts in this table.

```{r}
knitr::kable(dunique %>% arrange(desc(WMS)),caption = "Overview of number of geoservice combination by unique layer title", booktabs = TRUE) %>%  kable_classic(font_size = 10)
```

The next table shows for each service provider over all service the number of unique names, titles, groups and trees. If the group tag was empty then that layer does not belong to a group and is listed in the *unique title without group* column.

```{r}
knitr::kable(dgroup,caption = "Count of unique occurence for each service provider for usage of titles, names, groups and trees", booktabs = TRUE, col.names = names(dgroup) %>% str_replace_all("_"," ")) %>%  kable_classic(font_size = 10)
```

Not all services are configured in the same way some contain empty invalid name fields such as "0".

```{r}
knitr::kable(dnameInvalid,caption = "Service Provides where services named as *0*", booktabs = TRUE) %>%  kable_classic(font_size = 10)
```


# Metadata
Completeness of metadata description for OGC Web Services in Switzerland

```{r}
# Explorative filter Tests with search for keywords with str_detect
# geoCH %>% filter(str_detect(contact, 'deutschkurse|rebbau'))
# geoCH %>% filter(str_detect(keywords, 'wfs|wms|wmts'))
# geoCH %>% filter(str_detect(provider, 'Geodienste')) %>% select(provider,contact,title) %>% head()
# https://ows.geo.tg.ch/geofy_access_proxy/deutschkurse/?service=wms&request=GetCapabilities


# Dienstmetadaten enthalten: Title, Abstrakt (mit mehr als X Buchstaben), Keywords, URL zu Metadaten, Kontaktdaten
library(stringr)
# abstract
geoCH$metaAbstract <- nchar(geoCH$abstract)
geoCH$metaAbstractWordCount <- str_count(geoCH$abstract, '\\w+')
# Title vs Abstract duplication check
geoCH$titleDuplicated <- geoCH$title == geoCH$abstract

# keywords
# remove "null, ", "null" entries
geoCH$metaKeywords <- gsub("n.a.","",geoCH$keywords)
geoCH$metaKeywords <- gsub("null, ","",geoCH$metaKeywords)
geoCH$metaKeywords <- gsub("null","",geoCH$metaKeywords)
geoCH$metaKeywordsFilled <- nchar(geoCH$metaKeywords)
# remove urls in keywords
geoCH$metaKeywords <- gsub("(f|ht)tp(s?)://\\S+", "", geoCH$metaKeywords, perl=T) # remove url
# detect urls in Keywords
geoCH$metaKeywordsURL <- str_count(geoCH$keywords, '(f|ht)tp(s?)://\\S+')
# detect keywordlist identifier in keywords (Bund) e.g. ch.swisstopo-karto.hangneigung.wms_ows_keywordlist
geoCH$metaKeywordsList <- str_count(geoCH$keywords, 'keywordlist')
# count keywords by comma separation
geoCH$metaKeywordsCountComma <- str_count(geoCH$metaKeywords, ",")
geoCH$metaKeywordsCountComma <- ifelse(geoCH$metaKeywordsFilled>0,geoCH$metaKeywordsCountComma+1,geoCH$metaKeywordsCountComma)
# metaKeywordsCountComma counts keywordslists as 1 
geoCH$metaKeywordsCountComma <- geoCH$metaKeywordsCountComma - geoCH$metaKeywordsList

# count keywords by word detection
# problem is that it counts the following ch.bafu.something as 3
geoCH$metaKeywordsCountWord <- str_count(geoCH$metaKeywords, '\\w+')
geoCH$metaMetadata <- nchar(geoCH$metadata)

# contact information 
# not sure if it's depicted correctly as many entries contain urls 
# leading to nowhere
geoCH$metaContact <- gsub("n.a.","",geoCH$contact)
geoCH$metaContact <- nchar(geoCH$metaContact)
geoCH$metaContactCountAt <- str_count(geoCH$contact, "@")

# test counts with random rows in the dataset
# geoCH %>% select(abstract,metaAbstractWordCount) %>% filter(nchar(abstract)>0) %>% sample_n(8)
# geoCH %>% select(keywords,metaKeywordsCount,metaKeywordsCount2) %>% filter(nchar(keywords)>0) %>% sample_n(8)
# geoCH %>% select(keywords,metaKeywordsURL,metaKeywordsFilled) %>% filter(nchar(metaKeywordsFilled)>0) %>% sample_n(8)
# geoCH %>% select(contact,metaContact,metaContactCountAt) %>% filter(nchar(contact)>0) %>% sample_n(30)
# dbund <- geoCH %>% select(title,provider, keywords,metaKeywordsCount,metaKeywordsCount2,metaKeywordsURL,metaKeywordsList) %>% filter(provider=="Bund",nchar(keywords)>0)
# geoCH %>% filter(metaKeywordsFilled>0) %>% select(provider, keywords, metaKeywords) %>% head(n=30)
# geoCH %>% filter(metaKeywordsFilled>0) %>% select(provider, keywords, metaKeywords, metaKeywordsCountComma,metaKeywordsCountWord) %>% head(n=30)


dMeta <- geoCH %>% group_by(provider)  %>% summarise(
  n=n(),
  abstract = sum(metaAbstract>0),
  keywords = sum(metaKeywordsFilled>0),
  keywordsURL = sum(metaKeywordsURL>0),
  keywordsList = sum(metaKeywordsList>0),
  titleDuplicated = sum(titleDuplicated>0),
  keywordsURLList = sum(metaKeywordsList>0|metaKeywordsURL>0),
  abstractWords = sum(metaAbstractWordCount,na.rm=T), # mit leeren Abstracts
  abstractWordsMedian0 = median(metaAbstractWordCount,na.rm=T), # mit leeren Abstracts
  abstractWordsMedian = ifelse(abstract,median(metaAbstractWordCount[metaAbstractWordCount>0],na.rm=T),0),
  keywordsMedian0 = median(metaKeywordsCountComma,na.rm=T),
  keywordsMedianURL = median(metaKeywordsURL+keywordsList,na.rm=T),
  # if clause for providers with no valid keyword count
  keywordsMedian = ifelse(length(metaKeywordsCountComma[metaKeywordsCountComma>0])>0,median(metaKeywordsCountComma[metaKeywordsCountComma>0],na.rm=T),0),
  contact = sum(metaContact>0),
  contactAt = sum(metaContactCountAt>0),
  abstractPerc = abstract/n*100,
  keywordsPerc = keywords/n*100,
  keywordsURLListPerc = keywordsURLList/n*100,
  titleDuplicatedPerc = titleDuplicated/n*100,
  contactPerc = contact/n*100,
  contactAtPerc = contactAt/n*100,
) %>% as.data.frame()

dMeta$provider <- gsub("KT_","",dMeta$provider)
dMeta$provider <- gsub("FL_","",dMeta$provider)
levelProvider <- c(dMeta$provider[-which(dMeta$provider=="LI")],dMeta$provider[which(dMeta$provider=="LI")])  # umsortieren mit LI am Ende
dMeta$provider <- factor(dMeta$provider, level = levelProvider)
```

```{r}
#| fig-cap: Metadata coverage per service provider
#| fig-height: 5
# names(dMeta) <- c("provider", "n", "abstract","Keywords", "2 Keywords", "Contact", "Contact Email", "abstractPerc", "Keywords %", "2 Keywords %", "Kontaktangaben %","Email %")
dLong <- dMeta %>% pivot_longer(cols=c("abstractPerc"  , "keywordsPerc" ,  "contactPerc"), names_to = "key", values_to = "values") %>% 
  mutate(key = str_replace(key, "abstractPerc", "Abstract filled %"),
         key = str_replace(key, "keywordsPerc", "Keywords filled %"),
         key = str_replace(key, "contactPerc", "Contact filled %")) %>% as.data.frame()

dLong2 <- dMeta %>% pivot_longer(cols=c("abstractWordsMedian"  ,"keywordsMedian", "contactAtPerc", "titleDuplicatedPerc"), names_to = "key", values_to = "values") %>% 
  mutate(key = str_replace(key, "abstractWordsMedian", "Abstract Wordcount Median"),
         key = str_replace(key, "keywordsMedian", "Keywords Wordcount Median"),
         # key = str_replace(key, "keywordsURLListPerc", "Keywords URL %"),
         key = str_replace(key, "titleDuplicatedPerc", "Title duplicated %"),
         key = str_replace(key, "contactAtPerc", "Email %")) %>% as.data.frame()
```

```{r}
#| fig-cap: Metadata usage in OGC Web Servics Switzerland, percentage of abstrace, keywords and contact information filled for each data provider
#| fig-height: 5
ggplot(data = dLong, aes(x=provider, y= values)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  # geom_text(aes(label = format(values, digits=1, nsmall=1)), nudge_y = 2,size=3, color = "black",hjust = 0)+
  # scale_y_continuous(expand = expansion(mult = c(0, .01)), limits = c(0,100))+
  coord_flip() + 
  scale_x_discrete(limits = rev(unique(sort(dLong$provider))))+
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank(),strip.background = element_rect(fill = "white"))+
  facet_wrap(~factor(key, c("Abstract filled %", "Keywords filled %", "Contact filled %")),nrow=1) +
  # labs(title = "Metadaten", subtitle= "Verwendung von Metadatenfeldern im OWS",x = NULL,y = NULL,fill="",caption=caption)
  labs(title = "Metadata", subtitle= "Usage of metadata fields in OWS",x = NULL,y = NULL,fill="",caption=caption)
```

```{r}
#| fig-cap: Metadata usage in OGC Web Servics Switzerland, Median Wordcount for abstract and keywords, percentage of keyword entries that contain an url or an identifier, percentage of email addresses provided in the contact fields for each provider, percentage of abstract that are exact duplicates of the title
#| fig-height: 5
ggplot(data = dLong2, aes(x=provider, y= values)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  # geom_text(aes(label = format(values, digits=1, nsmall=1)), nudge_y = 2,size=3, color = "black",hjust = 0)+
  scale_y_continuous(expand = expansion(mult = c(0, .1)))+
  coord_flip() + 
  scale_x_discrete(limits = rev(unique(sort(dLong$provider))))+
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank(),strip.background = element_rect(fill = "white"))+
  # facet_wrap(~key,nrow=1, scales = "free_x")+
  facet_wrap(~factor(key, c("Abstract Wordcount Median", "Keywords Wordcount Median", "Email %", "Title duplicated %")),nrow=1, scales = "free_x")+
  # labs(title = "Metadata", subtitle= "Usage of metadata fields in OWS",x = NULL,y = NULL,fill="",caption=caption)
  labs(title = "Metadaten", subtitle= "Verwendung der Metadatenfeldern in OWS",x = NULL,y = NULL,fill="",caption=caption)
```
Median Word Count in Abstracts `r median(geoCH$metaAbstractWordCount, na.rm=T)`, without empty abstracts `r geoCH %>% filter(metaAbstractWordCount>0) %>% summarise(medianWordCount=median(metaAbstractWordCount,na.rm=T)) %>% as.vector()`
Median Word Count in Keywords `r median(geoCH$metaKeywordsCountComma, na.rm=T)`, without empty keywords `r geoCH %>% filter(metaKeywordsCountComma >0) %>% summarise(medianKeywordCount=median(metaKeywordsCountComma,na.rm=T)) %>% as.vector()`


# Spatial Coverage of Geoservices

```{r}
# create bounding boxes from services

# convert bounding box string to a polygon 
# eg. "2740443.137 1232276.032 2765413.73 1258037.171 EPSG:2056"
# https://github.com/r-spatial/sf/issues/1034
str2BBox <- function(bboxString){
  i = 0
  res <- lapply(bboxString,function(str){
    i <- i +1
    # extract coordinates and EPSG Code
    x <- unlist(strsplit(str ," "))
    x <- x[x != ""] # remove empty strings
    # return an empty polygon if coordinates are missing
    if(length(x)==0){return(st_polygon())} 
    # epsg <- as.numeric(unlist(strsplit(x[5] ,":"))[2])
    x <- as.numeric(x[1:4])
    if(anyNA(x)){cat(i,": ",x,"has NA")}
    # create a bounding box polygon
    x <- st_polygon(list(cbind(
          c(x[1],x[3],x[3],x[1],x[1]), # x coords 
          c(x[2],x[2],x[4],x[4],x[2])  # y coords
          )))
    return(x)
  })
  return(res)
}

# extract coordinates and EPSG Code
# eg. "2740443.137 1232276.032 2765413.73 1258037.171 EPSG:2056"
str2EPSG <- function(bboxString){
  res <- lapply(bboxString,function(str){
    epsg <- as.numeric(unlist(strsplit(str,":"))[2])
    return(epsg)
  })
  return(unlist(res))
}
```

```{r}
# generate sf bounding boxes from bbox string as epsg
geoBBox <- str2BBox(geoCH[,"bbox"])
geoBBoxStr <- lapply(geoBBox,st_as_text)
geoCHSF <- st_sf(geoCH,geoBBox)
geoCHSF$epsg <- 4326
geoCH$epsg <- 4326
geoCHSF$isEmpty <- st_is_empty(geoCHSF) # which polygons have no geometries

dsf <- geoCHSF %>% filter(epsg==4326)
st_crs(dsf) <- 4326 
dsf <- st_transform(dsf, 2056)

```

```{r, eval=FALSE}
# generate sf bounding boxes
geoBBox <- str2BBox(geoCH[,"bbox"])
geoEPSG <- str2EPSG(geoCH$bbox)
geoBBoxStr <- lapply(geoBBox,st_as_text)

geoCHSF <- st_sf(geoCH,geoBBox)
geoCHSF$epsg <- str2EPSG(geoCH$bbox)
geoCHSF$isEmpty <- st_is_empty(geoCHSF) # which polygons have no geometries

geoCH$epsg <- str2EPSG(geoCH$bbox)
geoCH$isEmpty <- st_is_empty(geoCHSF) # which polygons have no geometries
# geoCH$bboxStr <- lapply(geoBBox,st_as_text)
```

```{r, eval=FALSE}
# EPSG Count
d <- geoCH %>% group_by(epsg) %>% summarise(epsg = first(unique(epsg)), n = n())
knitr::kable(d, digits = 2,row.names=FALSE,caption = "Frequency of CRS provided for Geoservies in CH (epsg)", booktabs = TRUE,caption.short = "EPSG")  %>% column_spec(2,width="8 cm") %>%  kable_classic(font_size = 12)
```

```{r, eval=FALSE}
#| fig-cap: Frequency of CRS provided for Geoservies in CH (epsg)
#| fig-height: 2
ggplot(data = d, aes(x=reorder(epsg,n), y= n)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  geom_text(aes(label = n), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
   scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  labs(title = "Distribution of CRS by Dataset", subtitle= "Frequency of EPSG Occurence",x = NULL,y = "Count",fill="",caption=caption)

```

```{r, eval=FALSE}
# dsf <- geoCHSF %>% filter(epsg==2056)
# st_crs(dsf) <- 2056

ggplot() + themeReport  +
  geom_sf(data = cantonSF,fill=NA, colour="#cccccc",size=0.25) +
  geom_sf(data = lakesSF, fill="#a6cee3", color="#a6cee3",alpha=0.6,size=0.25) +
  geom_sf(data = dsf,fill=NA, colour="#ff660020",size=0.25) +
  labs(title = "GeoServices Switzerland",subtitle = "Spatial Coverage of the Bounding Boxes",fill = "",x = NULL,y = NULL,colour="", caption=paste(caption,", BFS",sep=""))+coord_sf(datum = NA)
```

```{r}
#| fig-cap: Spatial Coverage of the bounding boxes for all the provided datasets with the map extent set to Switzerland. Extends exceeding these bounds are not depicted.
#| fig-height: 6
# dsf <- geoCHSF %>% filter(epsg==2056)
# st_crs(dsf) <- 2056
# bbox of switzerland
# st_bbox(cantonSF)
# 2485202 1075281 2834036 1295864 
# 2400000 1000000 2850000 1300000 


box = c(xmin = 2400000, ymin = 1000000, xmax = 2850000, ymax = 1300000)
dsf <- st_crop(dsf,box )


ggplot() + themeReport  +
  geom_sf(data = cantonSF,fill=NA, colour="#cccccc",size=0.25) +
  geom_sf(data = lakesSF, fill="#a6cee3", color="#a6cee3",alpha=0.6,size=0.25) +
  geom_sf(data = dsf,fill=NA, colour="#ff660020",size=0.25,alpha=0.005) +
  labs(title = "GeoServices Switzerland",subtitle = "Spatial Coverage of the Bounding Boxes with EPSG 2056",fill = "",x = NULL,y = NULL,colour="", caption=paste("Map extent set to Switzerland, ",caption,", BFS",sep=""))+coord_sf(datum = NA)

```
# Word Clouds
Word clouds generated for OGC Web Services metadata entries title, abstract and keywords. URLs and identifiers are filtered out for better depiction of word usage rather than repetitive urls.

```{r}
# generate word cloud from service title, abstract, keywords
library(tm)
library(wordcloud)
library(RColorBrewer)
# function to create a clean text corpus
createCorpus <- function(text){
  docs <- Corpus(VectorSource(text))
  # remove url from text
  # https://stackoverflow.com/questions/41109773/gsub-function-in-tm-package-to-remove-urls-does-not-remove-the-entire-string
  removeURL <- content_transformer(function(x) gsub("(f|ht)tp(s?)://\\S+", "", x, perl=T))
  docs <- docs %>%
    tm_map(removeURL) %>% 
    tm_map(removeNumbers) %>%
    tm_map(removePunctuation) %>%
    tm_map(stripWhitespace)
  docs <- tm_map(docs, content_transformer(tolower))
  
  docs <- tm_map(docs, removeWords, stopwords("english"))
  docs <- tm_map(docs, removeWords, stopwords("german"))
  docs <- tm_map(docs, removeWords, stopwords("french"))
  docs <- tm_map(docs, removeWords, stopwords("italian"))
  return(docs)
}
createTermDocumentMatrix <- function(docs){
  dtm <- TermDocumentMatrix(docs) 
  matrix <- as.matrix(dtm) 
  words <- sort(rowSums(matrix),decreasing=TRUE) 
  df <- data.frame(word = names(words),freq=words)
  return(df)
}

# create a corpus with data cleaning
ctitle <- createCorpus(geoCH$title)
cabstract <- createCorpus(geoCH$abstract)
ckeywords <- createCorpus(geoCH$keywords)

# create a TermDocumentMatrix
tdmtitle <- createTermDocumentMatrix(ctitle)
tdmabstract <- createTermDocumentMatrix(cabstract)
tdmkeywords <- createTermDocumentMatrix(ckeywords)
```

```{r,warning=FALSE}
#| fig-cap: Word Cloud for word frequency of OGC Web Services titles
#| fig-height: 4
# create wordcloud
df <- tdmtitle
wordcloud(words = df$word, freq = df$freq, min.freq = 10, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(9, "Blues")[3:9])
```

```{r,warning=FALSE}
#| fig-cap: Word Cloud for word frequency of OGC Web Services abstracts
#| fig-height: 4
# create wordcloud
df <- tdmabstract
wordcloud(words = df$word, freq = df$freq, min.freq = 10, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(9, "Blues")[3:9])
```

```{r,warning=FALSE}
#| fig-cap: Word Cloud for word frequency of OGC Web Services keywords, omitting urls and identifiers
#| fig-height: 4
# create wordcloud
df <- tdmkeywords
wordcloud(words = df$word, freq = df$freq, min.freq = 10, max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(9, "Blues")[3:9])
```


```{r}
#| fig-cap: Most frequent Terms for Geoservice title 
#| fig-height: 6
d <- tdmtitle[1:50,]
ggplot(data = d, aes(x=reorder(word,freq), y= freq)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  geom_text(aes(label = freq), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
   scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  labs(title = "Geoservice Titles in Switzerland", subtitle= "Term Frequency",x = NULL,y = "Count",fill="",caption=caption)
```

```{r}
#| fig-cap: Most frequent Terms for Geoservice abstract 
#| fig-height: 4
d <- tdmabstract[1:25,]
ggplot(data = d, aes(x=reorder(word,freq), y= freq)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  geom_text(aes(label = freq), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
   scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  labs(title = "Geoservice abstracts in Switzerland", subtitle= "Term Frequency",x = NULL,y = "Count",fill="",caption=caption)
```

```{r}
#| fig-cap: Most frequent Terms for Geoservice keywords 
#| fig-height: 4

d <- tdmkeywords %>% filter(str_detect(word, 'http',negate=T)) 
d <- d[1:25,]
ggplot(data = d, aes(x=reorder(word,freq), y= freq)) + 
  geom_bar(stat = "identity",fill=colorPrimary) +
  geom_text(aes(label = freq), nudge_y = 2,size=3, color = "black",hjust = -0.2)+
   scale_y_continuous(expand = expansion(mult = c(0, .08)))+
  coord_flip() +
   theme(axis.line.x = element_line(size = .2),panel.background = element_blank(),axis.ticks.y=element_blank())+
  labs(title = "Geoservice keywords in Switzerland", subtitle= "Term Frequency",x = NULL,y = "Count",fill="",caption=caption)
```
